{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PD_proj2_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamemc/PD_02/blob/EMC/PD_202021_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcgwnRfLgHaf"
      },
      "source": [
        "# Data Mining / Prospecção de Dados\n",
        "\n",
        "## Diogo F. Soares and Sara C. Madeira, 2020/21\n",
        "\n",
        "# Project 2 - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjLy5zShgHat"
      },
      "source": [
        "## Logistics \n",
        "\n",
        "**_Read Carefully_**\n",
        "\n",
        "**Students should work in teams of 2 or 3 people**. \n",
        "\n",
        "Individual projects might be allowed (with valid justification), but will not have better grades for this reason. \n",
        "\n",
        "The quality of the project will dictate its grade, not the number of people working.\n",
        "\n",
        "**The project's solution should be uploaded in Moodle before the end of `April, 18th (23:59)`.** \n",
        "\n",
        "Students should **upload a `.zip` file** containing all the files necessary for project evaluation. \n",
        "Groups should be registered in [Moodle](https://moodle.ciencias.ulisboa.pt/mod/groupselect/view.php?id=139096) and the zip file should be identified as `PDnn.zip` where `nn` is the number of your group.\n",
        "\n",
        "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. Projects not delivered in this format will not be graded. You can use `PD_202021_P2.ipynb`as template. In your `.zip` folder you should also include an HTML version of your notebook with all the outputs** (File > Download as > HTML).\n",
        "\n",
        "**Decisions should be justified and results should be critically discussed.** \n",
        "\n",
        "_Project solutions containing only code and outputs without discussions will achieve a maximum grade 10 out of 20._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPNMHG2UgHau"
      },
      "source": [
        "## Dataset and Tools\n",
        "\n",
        "In this project you should use [Python 3](https://www.python.org), [Jupyter Notebook](http://jupyter.org) and **[Scikit-learn](http://scikit-learn.org/stable/)**.\n",
        "\n",
        "The dataset to be analysed is **`medulloblastoma_genes.csv`**. It includes 76 samples of medulloblastoma (MB) with respective expression levels of 54.675 genes measured in children with ages between 3 and 16 years. Medulloblastoma is a malignant childhood brain tumour comprising four discrete subgroups. \n",
        "\n",
        "In this project you will consider the labels of the samples included in the `labels.csv` file where samples are labelled as MB-CL or Other. In this case, we have 51 samples of classic medulloblastoma (MB-CL) and 25 other types (namely: 6 desmoplastic nodular, 17 anaplastic and 2 medullomyoblastoma).\n",
        "\n",
        "In `medulloblastoma_genes.csv` each line represents a sample and each column represents a gene.\n",
        "\n",
        "\n",
        "**The goal is to cluster samples and (ideally) find \"MB-CL\" groups and \"Other MB\" groups.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ou1gN7mgHaw"
      },
      "source": [
        "## Team Identification\n",
        "\n",
        "**GROUP NNN**\n",
        "\n",
        "Students:\n",
        "\n",
        "* Student 1 - n_student1\n",
        "* Student 2 - n_student2\n",
        "* Student 3 - n_student3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5cgX4OKgHax"
      },
      "source": [
        "## 1. Load and Preprocess Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jdu8-3GgHay"
      },
      "source": [
        "At the end of this step you should have:\n",
        "* a 76 rows × 54675 columns matrix, **X**, containing the values of the 54675 features for each of the 76 samples.\n",
        "* a vector, **y**, with the 76 type of medulloblastoma, which you can use later to evaluate clustering quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_6KhFQ9gHaz"
      },
      "source": [
        "# Write code in cells like this ...\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "df=pd.read_csv('/content/medulloblastoma_genes.csv')\n",
        "df2=pd.read_csv('/content/labels.csv')"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYGI4lacqtQD"
      },
      "source": [
        "X, y = df.iloc[:, 1:].values, df2.iloc[:, 1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                     test_size=0.3, \n",
        "                     random_state=0, \n",
        "                     stratify=y)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r934_PYgHa0"
      },
      "source": [
        "## 2. Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9j7y-UugHa1"
      },
      "source": [
        "As you already noticed the number of features (genes) is extremely high when compared to the number of objects to cluster (samples). In this context, you should perform dimensionality reduction, that is, reduce the number of features, in two ways:\n",
        "\n",
        "* [**Removing features with low variance**](http://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "\n",
        "* [**Using Principal Component Analysis**](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
        "\n",
        "At the end of this step you should have two new matrices with the same number of rows, each with a different number of columns (features): **X_variance** and **X_PCA**. \n",
        "\n",
        "**Don't change X you will need it!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s_WjLO2gHa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "7595ed9f-4c5c-424c-87cc-adeaf6995146"
      },
      "source": [
        "##variancia select\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X_variance = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
        "X_variance = X_variance.fit_transform(X_train)\n",
        "#X_variance.fit_transform(X_train)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-3a3ad2cd29c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_variance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_variance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'fit_transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDuoVNxnqxrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1ade7c-00b0-486b-ad48-b3cd6032a9cf"
      },
      "source": [
        "#standarizar os values das features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "stdsc = StandardScaler()\n",
        "X_train_std = stdsc.fit_transform(X_train)\n",
        "X_test_std = stdsc.transform(X_test)\n",
        "\n",
        "#pca\n",
        "from sklearn.decomposition import PCA\n",
        "X_PCA = PCA(n_components=3)\n",
        "X_PCA = pca.fit(X_train_std)\n",
        "\n",
        "print(\"The components matrix\")\n",
        "print(X_PCA.components_)\n",
        "print(\"\\nExplained variances:\", pca.explained_variance_)\n",
        "print(\"\\nRatio of explained variance\",pca.explained_variance_/sum(pca.explained_variance_))\n",
        "#this last line could be replaced by the following but the undelying principle would be lost\n",
        "#print(\"\\nRatio of explained variance\",pca.explained_variance_ratio_)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The components matrix\n",
            "[[ 0.0039918  -0.00426219 -0.00240913 ... -0.00068159  0.00245447\n",
            "   0.00739426]\n",
            " [ 0.00085101  0.00051193  0.00606239 ... -0.00079261  0.00264612\n",
            "   0.003852  ]\n",
            " [ 0.00782113 -0.00110036  0.00338355 ... -0.00555002 -0.00165173\n",
            "  -0.00105941]]\n",
            "\n",
            "Explained variances: [5236.30830434 4337.12343007 2798.4844519 ]\n",
            "\n",
            "Ratio of explained variance [0.4232415  0.35056198 0.22619653]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLgtJzC1qxy7"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y_train_bin = []\n",
        "y_test_bin = []\n",
        "for i in y_train:\n",
        "  if i == 'MB-CL':\n",
        "    y_train_bin.append(1)\n",
        "  if i == 'Other':\n",
        "    y_train_bin.append(0)\n",
        "\n",
        "for i in y_test:\n",
        "  if i == 'MB-CL':\n",
        "    y_test_bin.append(1)\n",
        "  if i == 'Other':\n",
        "    y_test_bin.append(0)\n",
        "\n",
        "X_train_dr = pca.transform(X_train_std)\n",
        "X_test_dr  = pca.transform(X_test_std)\n",
        "\n"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHfhjSzMqx3f"
      },
      "source": [
        "X_train_dr = pca.transform(X_train_std)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDqnnbEOgHa4"
      },
      "source": [
        "## 3. Clustering Samples using Partitional Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntQXlyNAgHa6"
      },
      "source": [
        "Use **`K`-means** to cluster the samples:\n",
        "\n",
        "* Cluster the original data (54.675 features): **X**.\n",
        "    * Use different values of `K`.\n",
        "    * For each value of `K` present the clustering by specifying how many samples MB-CL and Other are in each cluster.     \n",
        "    For instance, `{0: {'MB-CL': 51, 'Other': 0}, 1: {'MB-CL': 0, 'Other': 25}}` is the ideal clustering that we aimed at obtained with K-means when `K=2`, where the first cluster has 51 MB-CL samples and 0 Other samples and the second cluster has 0 MB-CL samples and 25 Other samples.\n",
        "    You can choose how to output this information.  **Tip**: You can explore the usage of contigency matrices.\n",
        "    * What is the best value of `K` ? Justify using the clustering results and the [Silhouette score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html).\n",
        "\n",
        "* Cluster the data obtained after removing features with low variance: **X_variance**.\n",
        "    * Study different values of `K` as above.\n",
        "\n",
        "* Cluster the data obtained after applying PCA: **X_PCA**.\n",
        "    * Study different values of `K` as above.\n",
        "\n",
        "* Compare the results obtained in the three datasets above for the best `K`. \n",
        "* Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PWIGNQRgHa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8151900-9165-489c-bce9-4e3eb7aecb1a"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=1, random_state=0)\n",
        "kmeans = kmeans.fit(X_train_dr)\n",
        "#X_train, X_test\n",
        "kmeans = kmeans.cluster_centers_\n",
        "#kmeans.labels_\n",
        "\n",
        "kmeans"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.48568135e-15, -2.21206701e-15, -1.07251734e-15]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYCzZo4KgHa7"
      },
      "source": [
        "## 4. Clustering Samples using Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvW5iQOOgHa8"
      },
      "source": [
        "Use a **Hierarchical Clustering Algorithm (HCA)** to cluster the samples: \n",
        "\n",
        "* Cluster the data in **X_variance**.\n",
        "    * Use **different linkage metrics**.\n",
        "    * Use different values of `K`.\n",
        "    * For each linkage metric and value of `K` present the clustering by specifying how many MB-CL and Other samples are in each cluster as you did before. \n",
        "    * What is the best linkage metric and the best value of `K`? Justify using the clustering results and the [Silhouette score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html).\n",
        "\n",
        "* Cluster the data in **X_PCA**.\n",
        "    * Study different linkage metrics and different values of `K` as above.\n",
        "\n",
        "* Compare the results obtained in the two datasets above for the best linkage metric and the best `K`. \n",
        "* Discuss the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifqFeSBsgHa8"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au9REg0QgHa9"
      },
      "source": [
        "## 5. Evaluating Clustering Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X3R6kgOgHa9"
      },
      "source": [
        "In this task you should compare the best results obtained using `K`-means and HCA \n",
        "1. **Without using ground truth**\n",
        "2. **Using ground truth (`Medulloblastoma Type`)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr7OEBL3gHa-"
      },
      "source": [
        "### 5.1. Without Using Ground Truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGRLCEvFgHa-"
      },
      "source": [
        "**Choose one adequate measure** from those available by Sciki-learn (https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation) to evaluate the different clusterings. \n",
        "\n",
        "Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMuVmN3gHa_"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzWVDzk0gHa_"
      },
      "source": [
        "### 5.2. Using Ground Truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdDYzM3gHbA"
      },
      "source": [
        "**Choose one adequate measure** from those available by Sciki-learn (https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation) to evaluate the different clusterings. \n",
        "\n",
        "Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBA-AEiCgHbA"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEPZbrLJgHbA"
      },
      "source": [
        "## 6. Clustering Samples using Density-based Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGKXwic5gHbC"
      },
      "source": [
        "Use DBSCAN (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) or OPTICS (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html) to cluster the samples.\n",
        "\n",
        "Compare the results with those of K-means and HCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCAMOg5xgHbC"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUUxPfKNgHbD"
      },
      "source": [
        "## 7. Choose a Different Clustering Algorithm to Group the Samples\n",
        "\n",
        "Choose **a clustering algorithm** besides `K`-means, HCA and DBSCAN/OPTICS to cluster the samples. \n",
        "\n",
        "**Groups of 3 People** must choose two different algorithms.\n",
        "\n",
        "Justify your choice and compare the results with those of `K`-means, HCA and DBSCAN/OPTICS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw11lO9TgHbD"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3eMghytgHbE"
      },
      "source": [
        "## 8. Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-J7U1AgHbE"
      },
      "source": [
        "Draw some conclusions about this project work. Can you highlight some insights about meduloblastoma types? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eFOGLiQgHbE"
      },
      "source": [
        "# Write code in cells like this ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQZbHT_tgHbF"
      },
      "source": [
        "Write text in cells like this..."
      ]
    }
  ]
}